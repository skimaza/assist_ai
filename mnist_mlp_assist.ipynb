{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuZRbjIk4GE5kpSaIBy65x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skimaza/assist_ai/blob/main/mnist_mlp_assist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j3a7hs95ZEK"
      },
      "source": [
        "# 딥러닝의 이해\n",
        "# Multilayer Perceptron 실습 예제\n",
        "# MLP를 이용한 MNIST 필기체 숫자 인식\n",
        "## MNIST dataset: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlBGjhch57W6"
      },
      "source": [
        "# 라이브러리 import\n",
        "- numpy: number를 다루는 라이브러리(패키지)\n",
        "- torch: PyTorch 딥러닝 프레임워크 라이브러리\n",
        "- torchvision: PyTorch로 이미지 데이터를 다루는 라이브러리\n",
        "- matplotlib: 이미지와 그래프 표시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3J4J2Rvhd33"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbHkck8vwfxf"
      },
      "source": [
        "# Colab으로 배정된 가상머신 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jbefE2I0tWv"
      },
      "source": [
        "### 현재 디렉토리(폴더)\n",
        "### '!'로 시작하는 명령은 가상머신의 명령을 실행하라는 의미"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ETk-qJ88pvF"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cx-x7Fn1Bz-"
      },
      "source": [
        "### 현재 디렉토리의 내용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wby95NM28sLG"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ugGXZQ1PWj"
      },
      "source": [
        "### sample_data directory에는 Google Colab에서 기본으로 제공하는 데이터가 있음\n",
        "### (이번 강의에서 사용할 데이터는 아님)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg78_RBm1Lkc"
      },
      "source": [
        "!ls sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9esMsv6ZNR"
      },
      "source": [
        "# PyTorch에서 제공하는 공개 데이터셋 라이브러리 사용\n",
        "transform parameter는 데이터셋에 자동으로 적용할 데이터 변환 기능.  \n",
        "여기서는 데이터값을 파이토치 Tensor로 바꾸는 기능만 사용.  \n",
        "데이터의 값을 정규화하거나 일부를 잘라내거나 회전하거나 하는 등의 데이터 augmentation을 지정할 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMMs-JSbCM_3"
      },
      "source": [
        "transform = transforms.ToTensor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NzQI121818"
      },
      "source": [
        "torchvision에서 import한 datasets 모듈을 이용해서 미리 정의된 MNIST 데이터셋을 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQ7ziAZ6O9G"
      },
      "source": [
        "# choose the training and testing datasets\n",
        "train_data = datasets.MNIST(root = 'data', train = True, download = True, transform = transform)\n",
        "test_data = datasets.MNIST(root = 'data', train = False, download = True, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu6tzx49gXx"
      },
      "source": [
        "# 다운로드된 디렉토리 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyljWyX43IZ2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCv7YPMF3LZL"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HJuZe8u3N65"
      },
      "source": [
        "!ls -l data/MNIST/raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6dbh8fK6EDM"
      },
      "source": [
        "# 아래 코드는 다운로드가 안 되는 경우를 위한 코드\n",
        "# 각 라인 앞의 '#'을 지우고 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVuMs8UH49Cj"
      },
      "source": [
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1dxPHAbkrdwcG6SuDXtL5M7JANouZ8dsJ' -O mnist_alt.tgz\n",
        "# !tar xzf mnist_alt.tgz\n",
        "# # choose the training and testing datasets\n",
        "# train_data = datasets.MNIST(root = 'data', train = True, download = False, transform = transform)\n",
        "# test_data = datasets.MNIST(root = 'data', train = False, download = False, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oAygvjt7vVa"
      },
      "source": [
        "# 다운로드된 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQerthlhfcyU"
      },
      "source": [
        "type(train_data), type(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM90UWcWe9ro"
      },
      "source": [
        "print(train_data)\n",
        "print(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LjYWMcT83T6"
      },
      "source": [
        "# 전체 데이터 수와 타입 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_MJVCMnfmCF"
      },
      "source": [
        "len(train_data), type(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fSD4hY-9HHJ"
      },
      "source": [
        "# 첫번째 데이터의 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPFwcAggMj_"
      },
      "source": [
        "len(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "id": "F1xGaq0EHAlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIlOH4UR90xI"
      },
      "source": [
        "train_data는 tuple 형태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCAw9qk59RAs"
      },
      "source": [
        "type(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LF6D_rX9WqU"
      },
      "source": [
        "len(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoLibTXN9-iC"
      },
      "source": [
        "튜플의 첫번 요소가 torch Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP6GFuW09NvB"
      },
      "source": [
        "type(train_data[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbB2423f-EY_"
      },
      "source": [
        "0번 데이터 튜플 중 첫번 요소인 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELBd6dPA9dTQ"
      },
      "source": [
        "train_data[0][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEn_KrCf9q8P"
      },
      "source": [
        "1개의 28x28 디멘션을 가지는 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "튜플의 두번째 요소는 label"
      ],
      "metadata": {
        "id": "0w0kK0REHMrt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOtcWRsJgWdx"
      },
      "source": [
        "train_data[0][1] # label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SP4NLYW-Jdr"
      },
      "source": [
        "train_data[0][0]에 대한 label. 즉 이미지가 표현하는 십진수  \n",
        "train_data[0]은 숫자 5에 대한 이미지(train_data[0][0])와 이에 대한 label, 5(train_data[0][1])의 쌍으로 구성된 튜플"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9jbAAAh9tr"
      },
      "source": [
        "## 값의 범위 확인\n",
        "처음 5개 데이터만 프린트해 본다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I67Xdo_nhVzd"
      },
      "source": [
        "for i in range(5):\n",
        "    print('Max value:', train_data[i][0].max())\n",
        "    print('Min Value:', train_data[i][0].min())\n",
        "    print('Label', train_data[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Vn1vtz-jo6"
      },
      "source": [
        "데이터셋의 처음 5개 데이터는 0과 1사이의 픽셀값을 갖는 흑백이미지이고 레이블은 각각 5, 0, 4, 1, 9이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P47Ev444-4Fr"
      },
      "source": [
        "# 첫번째 데이터의 일부분만 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_owSHqWqhJpM"
      },
      "source": [
        "train_data[0][0][:15, :15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHMVuPuy_C7Y"
      },
      "source": [
        "train_data 값의 형태 재확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxy7CxRDirXt"
      },
      "source": [
        "type(train_data[0][0]), train_data[0][0].shape, type(train_data[0][1]), train_data[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7ebawXZf2G7"
      },
      "source": [
        "### 이미지를 직접 보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X459mXn3_R-t"
      },
      "source": [
        "이미지를 디스플레이하기 위해 텐서를 numpy 배열로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r5aMELYirTP"
      },
      "source": [
        "img0 = train_data[0][0].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-eqPbq0_eYY"
      },
      "source": [
        "matplotlib 기능을 이용하여 디스플레이\n",
        "np.squeeze는 [1,28,28] 디멘션을 갖는 데이터에서 값이 1인 디멘션을 제거함"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img0.shape"
      ],
      "metadata": {
        "id": "5phsl55SWTkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue-dauYLkhOg"
      },
      "source": [
        "plt.imshow(np.squeeze(img0), 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    img = train_data[i][0].numpy()\n",
        "    print('Label:', train_data[i][1])\n",
        "    plt.imshow(np.squeeze(img), 'gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8dCSMnj7ICfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsjerQEl-4mG"
      },
      "source": [
        "# dataset에서 DataLoader를 구성\n",
        "torch.utils.data.DataLoader는 학습할 때 데이터를 차례대로 또는 랜덤으로 선택하여 넘겨주는 역할  \n",
        "train data와 valid data를 구분하여 학습용 데이터와 학습 상태를 검증하는 데이터로 사용  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU41SyZqB9yz"
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "# index를 shuffle\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_index, valid_index = indices[split:], indices[:split]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRohr0zu_1XC"
      },
      "source": [
        "train_index[:10], valid_index[:10], len(train_index), len(valid_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAwnYLcP_ors"
      },
      "source": [
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, \n",
        "                                           sampler = train_sampler, num_workers = num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n",
        "                                          sampler = valid_sampler, num_workers = num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, num_workers = num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WxImP3GAXtT"
      },
      "source": [
        "# loader에서 한번의 배치만 읽어서 내용 확인\n",
        "현재 batch_size를 20으로 지정한 상태임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkViTOUhirRf"
      },
      "source": [
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    # print out the correct label for each image\n",
        "    # .item() gets the value contained in a Tensor\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AZ0I5cvAsAZ"
      },
      "source": [
        "# 데이터 하나를 자세히 보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbEVM7DZirGg"
      },
      "source": [
        "img = np.squeeze(images[1])\n",
        "fig = plt.figure(figsize = (12,12)) \n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img, cmap='gray')\n",
        "width, height = img.shape\n",
        "thresh = img.max()/2.5\n",
        "for x in range(width):\n",
        "    for y in range(height):\n",
        "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "        ax.annotate(str(val), xy=(y,x),\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center',\n",
        "                    color='white' if img[x][y]<thresh else 'black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aSkeR3QAyDU"
      },
      "source": [
        "# fully connected layer 2개, 마지막 fully connected output layer가 1개인 Multilayer Perceptron 네트워크 정의\n",
        "### PyTorch에서는 class method인 forward에서 forward propagation을 정의하면 backward propagation 부분은 자동으로 구성해 줌 (autograd 기능)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt0UJFoYiO0H"
      },
      "source": [
        "# define NN architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP,self).__init__()\n",
        "        # number of hidden nodes in each layer (512)\n",
        "        hidden_1 = 512\n",
        "        hidden_2 = 512\n",
        "        # linear layer (784 -> hidden_1)\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        # linear layer (n_hidden -> hidden_2)\n",
        "        self.fc2 = nn.Linear(512,512)\n",
        "        # linear layer (n_hidden -> 10)\n",
        "        self.fc3 = nn.Linear(512,10)\n",
        "        # dropout layer (p=0.2) : zero 20% of input\n",
        "        # dropout prevents overfitting of data\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # flatten image input. 20개의 28*28 크기의 3차원 입력데이터([20,28,28])인 x를 28*28(=784) 크기의 2차원 데이터로 변환([20,784]).\n",
        "        # 여기서 정의한 MLP 네트워크에서는 2차원 정보를 이용하지 않음\n",
        "        x = x.view(-1,28*28)\n",
        "        # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "         # add hidden layer, with relu activation function\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # add dropout layer\n",
        "        x = self.dropout(x)\n",
        "        # add output layer\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im4wVMcQBjHS"
      },
      "source": [
        "# initialize the NN\n",
        "model = MLP()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01VcOw8mDClv"
      },
      "source": [
        "model은 784 -> 512 -> 512 -> 10 의 구조를 가진 MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frgQ9-t-DR4Y"
      },
      "source": [
        "# Loss (Error)는 분류 문제에 사용하는 CrossEntropyLoss를 사용\n",
        "# Gradient descent 알고리즘은 SGD(Stochastic Gradient Descent)를 사용\n",
        "# Learning rate는 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2DZcEkQiOwO"
      },
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8HyZJKvFFv9"
      },
      "source": [
        "# 학습 실행\n",
        "### n_epochs를 50으로 설정함\n",
        "### 학습 1번 완료 후 train_data의 loss와 valid_data의 loss와 비교\n",
        "### valid loss가 줄어들었으면 모델을 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXzAHKsqiOuV"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 50\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf  # set initial \"min\" to infinity\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor losses\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train() # prep model for training\n",
        "    for data,label in train_loader:\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output,label)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        \n",
        "     ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()  # prep model for evaluation\n",
        "    for data,label in valid_loader:\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output,label)\n",
        "        # update running validation loss \n",
        "        valid_loss += loss.item() * data.size(0) # bug\n",
        "    \n",
        "    # print training/validation statistics \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    valid_loss = valid_loss / len(valid_loader.sampler)\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JiPfuH4Itmj"
      },
      "source": [
        "# 저장된 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h1Udgu4iOpw"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg_Md95MIy1I"
      },
      "source": [
        "# test 데이터셋에 대해 인식률 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUmSUnrUiOoK"
      },
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "model.eval() # prep model for evaluation\n",
        "for data, target in test_loader:\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss \n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "SA1zskXjjqbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "id": "8zsvVQHnjaT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "id": "taPDGmGhjXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss"
      ],
      "metadata": {
        "id": "7ArKIYaXjUOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "qDGaNJWsjB28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct"
      ],
      "metadata": {
        "id": "Qtk4aw5ljIOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct"
      ],
      "metadata": {
        "id": "U1yZ827FjLTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_total"
      ],
      "metadata": {
        "id": "wO7MV1cdjNnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ug1_a6FI7-F"
      },
      "source": [
        "# 약 98% 정확도 달성\n",
        "# 실제 이미지를 보고 성능 확인\n",
        "아래 예제에서는 하나의 미니배치(20개) 이미지를 확인함  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPHJYC0qiObu"
      },
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "max_images = batch_size\n",
        "for idx in np.arange(max_images):\n",
        "    ax = fig.add_subplot(2, max_images/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azzStf5fsu8l"
      },
      "source": [
        "오류인 경우를 보기위해 틀릴 때까지 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIn4-BMjsrcL"
      },
      "source": [
        "fail = False\n",
        "for images, labels in dataiter:\n",
        "    # get sample outputs\n",
        "    output = model(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds = torch.max(output, 1)\n",
        "    # prep images for display\n",
        "    images = images.numpy()\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    for idx in np.arange(20):\n",
        "        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "        ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "        ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n",
        "        if preds[idx] != labels[idx]:\n",
        "            fail = True\n",
        "    plt.show()\n",
        "    if fail:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tTJz4-VKb8r"
      },
      "source": [
        "# 실습 종료"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvDxxr6wKhhS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}